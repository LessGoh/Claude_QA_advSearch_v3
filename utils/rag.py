from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
import logging
import streamlit as st

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def format_docs(docs):
    """Format retrieved documents with v3 metadata and detailed logging"""
    logger.info(f"Formatting {len(docs)} retrieved documents")
    
    if not docs:
        logger.warning("No documents retrieved!")
        return "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."
    
    formatted_content = []
    for i, doc in enumerate(docs):
        logger.info(f"Document {i+1}: {len(doc.page_content)} characters")
        logger.info(f"Document {i+1} metadata: {doc.metadata}")
        
        # Extract v3 metadata if available
        metadata = doc.metadata or {}
        
        # Build document header with enhanced metadata
        doc_header = f"[–î–æ–∫—É–º–µ–Ω—Ç {i+1}"
        
        # Add document title if available
        if 'document_title' in metadata:
            doc_header += f" - {metadata['document_title']}"
        elif 'filename' in metadata:
            doc_header += f" - {metadata['filename']}"
        
        # Add page number if available
        if 'page_num' in metadata:
            doc_header += f", —Å—Ç—Ä. {metadata['page_num']}"
        
        # Add section info if available  
        if 'section_title' in metadata:
            doc_header += f", —Ä–∞–∑–¥–µ–ª: {metadata['section_title']}"
        
        # Add content type indicators
        indicators = []
        if metadata.get('formula_count', 0) > 0:
            indicators.append(f"üìê —Ñ–æ—Ä–º—É–ª: {metadata['formula_count']}")
        if metadata.get('table_count', 0) > 0:
            indicators.append(f"üìä —Ç–∞–±–ª–∏—Ü: {metadata['table_count']}")
        if metadata.get('content_type') == 'mathematical':
            indicators.append("üî¢ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç")
        
        if indicators:
            doc_header += f" ({', '.join(indicators)})"
        
        doc_header += "]"
        
        # Format the content
        content = doc.page_content
        
        # Highlight mathematical formulas if they exist
        if metadata.get('formula_count', 0) > 0:
            content = content.replace('‚àÜ', 'Œî')  # Normalize Delta symbols
            content = content.replace('Œ¥', 'Œî')  # Normalize delta symbols
        
        formatted_content.append(f"{doc_header}\n{content}")
    
    result = "\n\n".join(formatted_content)
    logger.info(f"Total formatted content length: {len(result)} characters")
    
    # Count mathematical content
    math_indicators = sum(1 for doc in docs if doc.metadata.get('formula_count', 0) > 0)
    if math_indicators > 0:
        logger.info(f"Found {math_indicators} documents with mathematical formulas")
    
    return result

def ask_question(question, vectorstore):
    """Get answer to question using RAG with detailed logging"""
    logger.info(f"Processing question: {question[:100]}...")
    
    try:
        # Check vectorstore status
        logger.info(f"Vectorstore type: {type(vectorstore)}")
        
        # Try to get index stats if available
        try:
            if hasattr(vectorstore, '_index') and hasattr(vectorstore._index, 'describe_index_stats'):
                stats = vectorstore._index.describe_index_stats()
                logger.info(f"Index stats: {stats}")
        except Exception as e:
            logger.warning(f"Could not get index stats: {e}")
        
        # Enhanced search parameters for better mathematical content retrieval
        search_kwargs = {"k": 5}
        
        # Check if question contains mathematical terms
        math_terms = ['delta', '–¥–µ–ª—å—Ç–∞', 'vega', '–≤–µ–≥–∞', '—Ñ–æ—Ä–º—É–ª–∞', 'formula', '–æ–ø—Ü–∏–æ–Ω', 'option', 
                     '–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å', 'volatility', '‚àÜ', 'Œî', '–≥—Ä–µ–∫–∏', 'greeks']
        
        question_lower = question.lower()
        has_math_terms = any(term in question_lower for term in math_terms)
        
        if has_math_terms:
            logger.info("Mathematical terms detected in question, adjusting search parameters")
            # Increase retrieval count for mathematical queries
            search_kwargs["k"] = 8
            
            # Add filter for mathematical content if available
            search_kwargs["filter"] = {
                "formula_count": {"$gte": 0}  # Include documents with formulas
            }
        
        retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)
        
        # Test retrieval directly
        logger.info("Testing document retrieval...")
        try:
            retrieved_docs = retriever.get_relevant_documents(question)
            logger.info(f"Retrieved {len(retrieved_docs)} documents")
            
            # Log each retrieved document
            for i, doc in enumerate(retrieved_docs):
                logger.info(f"Retrieved doc {i+1}: content length={len(doc.page_content)}, metadata={doc.metadata}")
                logger.info(f"Retrieved doc {i+1} content preview: {doc.page_content[:200]}...")
                
        except Exception as e:
            logger.error(f"Direct retrieval failed: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {str(e)}"
        
        prompt_rag = PromptTemplate.from_template(
            """–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞—É—á–Ω—ã—Ö –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

            –ö–û–ù–¢–ï–ö–°–¢:
            {context}

            –í–û–ü–†–û–°: {question}

            –ò–ù–°–¢–†–£–ö–¶–ò–ò:
            - –û—Ç–≤–µ—á–∞–π—Ç–µ –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            - –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, ‚àÜc = e^(-qt_opt) ¬∑ N(d1)), –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ –∏—Ö —Ç–æ—á–Ω–æ
            - –û–±—ä—è—Å–Ω—è–π—Ç–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º
            - –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–æ—Ä–º—É–ª—ã –∏–ª–∏ —Ç–∞–±–ª–∏—Ü—ã, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∏—Ç–µ –∏—Ö –≤ –æ—Ç–≤–µ—Ç
            - –£–∫–∞–∂–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤), –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            - –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∏—Ç–µ: "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å"
            - –§–æ—Ä–º–∞—Ç–∏—Ä—É–π—Ç–µ –æ—Ç–≤–µ—Ç –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ø–∏—Å–∫–æ–≤ –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤

            –°–ü–ï–¶–ò–ê–õ–¨–ù–´–ï –ü–†–ê–í–ò–õ–ê:
            - Delta (Œî) - —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã –æ–ø—Ü–∏–æ–Ω–∞ –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Ü–µ–Ω—ã –±–∞–∑–æ–≤–æ–≥–æ –∞–∫—Ç–∏–≤–∞
            - Vega (V) - —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã –æ–ø—Ü–∏–æ–Ω–∞ –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—é –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            - –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∏ –≥—Ä–µ—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã
            - –û–±—ä—è—Å–Ω—è–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º—É–ª–∞—Ö

            –û–¢–í–ï–¢:"""
        )
        
        llm = ChatOpenAI(
            model_name="gpt-4o-mini", 
            temperature=0,
            max_tokens=1000
        )
        
        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt_rag
            | llm
        )
        
        # Log the chain execution
        logger.info("Executing RAG chain...")
        result = rag_chain.invoke(question)
        
        logger.info(f"Generated response length: {len(result.content)} characters")
        logger.info(f"Response preview: {result.content[:200]}...")
        
        # Display debug info in Streamlit for troubleshooting
        if st.session_state.get('debug_mode', False):
            with st.expander("üîç Debug Information"):
                st.write(f"**Question:** {question}")
                st.write(f"**Retrieved documents:** {len(retrieved_docs)}")
                for i, doc in enumerate(retrieved_docs):
                    st.write(f"**Document {i+1}:** {len(doc.page_content)} chars")
                    st.code(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                st.write(f"**Generated response:** {len(result.content)} chars")
        
        return result.content
    
    except Exception as e:
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}"
        logger.error(error_msg)
        logger.exception("Full exception details:")
        return error_msg